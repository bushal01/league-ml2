{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Encoding of Champions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import modules and load data\n",
    "2. Create word2vec training set of champ pairs\n",
    "3. Convert to OHE (and possible downsample for memory reasons)\n",
    "4. Train neural net\n",
    "5. Get weights from neural net\n",
    "6. Encode champs with weights from neural net and train neural net to predict match outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import modules and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Albert\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "# Project modules\n",
    "import get_modeling_data\n",
    "import model_evaluation.model_performance_functions as mpf\n",
    "import features.win_rates as wr\n",
    "import data_constants as dc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_modeling_data.get_train()\n",
    "validation = get_modeling_data.get_validation()\n",
    "train = train.fillna(0)\n",
    "validation = validation.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create word2vec training set of champ pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3386320, 2)\n",
      "  input output\n",
      "0  Jarv   Kata\n",
      "1  Shac   Malz\n",
      "2  Kled   Twis\n",
      "3  Pant   Morg\n",
      "4  Morg   Anni\n"
     ]
    }
   ],
   "source": [
    "word2vec_train = pd.DataFrame({'input': [], 'output': []})\n",
    "team_100_cols = ['100_TOP_SOLO', '100_MIDDLE_SOLO', '100_JUNGLE_NONE', '100_BOTTOM_DUO_CARRY', '100_BOTTOM_DUO_SUPPORT']\n",
    "word2vec_temp = pd.DataFrame({'input': [], 'output': []})\n",
    "blue_wins = train[train['team_100_win'] == 1]\n",
    "for col1 in team_100_cols:\n",
    "    for col2 in team_100_cols:\n",
    "        if col1 != col2:\n",
    "            word2vec_temp['input'] = blue_wins[col1]\n",
    "            word2vec_temp['output'] = blue_wins[col2]\n",
    "            word2vec_train = word2vec_train.append(word2vec_temp, ignore_index=True)\n",
    "\n",
    "team_200_cols = ['200_TOP_SOLO', '200_MIDDLE_SOLO', '200_JUNGLE_NONE', '200_BOTTOM_DUO_CARRY', '200_BOTTOM_DUO_SUPPORT']\n",
    "red_wins = train[train['team_100_win'] == 0]\n",
    "for col1 in team_200_cols:\n",
    "    for col2 in team_200_cols:\n",
    "        if col1 != col2:\n",
    "            word2vec_temp['input'] = blue_wins[col1]\n",
    "            word2vec_temp['output'] = blue_wins[col2]\n",
    "            word2vec_train = word2vec_train.append(word2vec_temp, ignore_index=True)\n",
    "print(word2vec_train.shape)\n",
    "print(word2vec_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Convert to OHE (and possible downsample for memory reasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_ts = word2vec_train.sample(500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "champs = dc.get_champs_four_letters()\n",
    "for champ in champs:\n",
    "    w2v_ts[champ + '_in'] = np.where(w2v_ts['input'] == champ, 1, 0)\n",
    "    w2v_ts[champ + '_out'] = np.where(w2v_ts['output'] == champ, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
